# OmniAI::Google

[![CircleCI](https://circleci.com/gh/ksylvest/omniai-google.svg?style=svg)](https://circleci.com/gh/ksylvest/omniai-google)

A Google implementation of the [OmniAI](https://github.com/ksylvest/omniai) APIs.

## Installation

```sh
gem install omniai-google
```

## Usage

### Client

A client is setup as follows if `ENV['GOOGLE_API_KEY']` exists:

```ruby
client = OmniAI::Google::Client.new
```

A client may also be passed the following options:

- `api_key` (required - default is `ENV['GOOGLE_API_KEY']`)
- `host` (optional)
- `version` (optional - options are `v1` or `v1beta`)

### Configuration

Global configuration is supported for the following options:

```ruby
OmniAI::Google.configure do |config|
  config.api_key = 'sk-...' # default: ENV['GOOGLE_API_KEY']
  config.host = '...' # default: 'https://generativelanguage.googleapis.com'
  config.version = OmniAI::Google::Config::Version::BETA # either 'v1' or 'v1beta'
end
```

### Chat

A chat completion is generated by passing in a simple text prompt:

```ruby
completion = client.chat('Tell me a joke!')
completion.text # 'Why did the chicken cross the road? To get to the other side.'
```

A chat completion may also be generated by using the prompt builder:

```ruby
completion = client.chat do |prompt|
  prompt.system('Your are an expert in geography.')
  prompt.user('What is the capital of Canada?')
end
completion.text # 'The capital of Canada is Ottawa.'
```

#### Model

`model` takes an optional string (default is `gemini-1.5-pro`):

```ruby
completion = client.chat('How fast is a cheetah?', model: OmniAI::Google::Chat::Model::GEMINI_FLASH)
completion.text # 'A cheetah can reach speeds over 100 km/h.'
```

[Google API Reference `model`](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versioning#gemini-model-versions)

#### Temperature

`temperature` takes an optional float between `0.0` and ` 2.0`:

```ruby
completion = client.chat('Pick a number between 1 and 5', temperature: 2.0)
completion.text # '3'
```

[Google API Reference `temperature`](https://ai.google.dev/api/rest/v1/GenerationConfig)

#### Stream

`stream` takes an optional a proc to stream responses in real-time chunks instead of waiting for a complete response:

```ruby
stream = proc do |chunk|
  print(chunk.text) # 'Better', 'three', 'hours', ...
end
client.chat('Be poetic.', stream:)
```

[Google API Reference `stream`](https://ai.google.dev/gemini-api/docs/api-overview#stream)
